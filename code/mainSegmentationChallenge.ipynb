{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def runTraining(modelName,checkpoints=None, n_epochs=0):\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 16\n",
    "    batch_size_val = 8\n",
    "    lr = 0.001\n",
    "    epoch = 10\n",
    "    start_epoch = 0\n",
    "    if checkpoints != None :\n",
    "        batch_size = checkpoints['batch_size']\n",
    "        batch_size_val = checkpoints['batch_size_val']\n",
    "        lr = checkpoints['lr']    # Learning Rate\n",
    "        epoch = n_epochs # Number of epochs\n",
    "        start_epoch = checkpoints['epoch']\n",
    "        \n",
    "\n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=False,\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "    \n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "    if checkpoints != None and checkpoints['model_state_dict'] != None:\n",
    "        net.load_state_dict = checkpoints['model_state_dict']\n",
    "    \n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax()\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    if checkpoints != None and checkpoints['optimizer_state_dict'] != None:\n",
    "        optimizer.load_state_dict = checkpoints['optimizer_state_dict']\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    if checkpoints != None :\n",
    "        Best_loss_val = checkpoints['val_loss']\n",
    "    BestEpoch = 0\n",
    "    \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(start_epoch, epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        lossValEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        num_batches_val = len(val_loader)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, _ = data\n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            # labels = torch.argmax(labels, dim=1)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net.forward(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(net_predictions, segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "            pred = softMax(net_predictions)\n",
    "            masks = torch.argmax(pred, dim=1)\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "            confmat = ConfusionMatrix(task=\"multiclass\", num_classes=4)\n",
    "            confmat = confmat(net_predictions, segmentation_classes).numpy()\n",
    "            accuracy = np.diag(confmat).sum()/confmat.sum()\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}, Acc: {}\".format(i,lossEpoch,accuracy))\n",
    "        net.eval()\n",
    "        for j, data_val in enumerate(val_loader):\n",
    "\n",
    "            images_val, labels_val, _ = data_val\n",
    "            labels_val = to_var(labels_val)\n",
    "            images_val = to_var(labels_val)\n",
    "            \n",
    "            net_predictions_val = net.forward(images_val.float())\n",
    "\n",
    "            segmentation_classes_val = getTargetSegmentation(labels_val)\n",
    "\n",
    "            CE_loss_value_val = CE_loss(net_predictions_val, segmentation_classes_val) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "\n",
    "            confmat_val = ConfusionMatrix(task=\"multiclass\", num_classes=4)\n",
    "            confmat_val = confmat_val(net_predictions_val, segmentation_classes_val).numpy()\n",
    "            accuracy_val = np.diag(confmat_val).sum()/confmat_val.sum()\n",
    "\n",
    "            lossValEpoch.append(CE_loss_value_val.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches_val,\n",
    "                             prefix=\"[Validation] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(CE_loss_value_val))\n",
    "\n",
    "        lossValEpoch = np.asarray(lossValEpoch)\n",
    "        lossValEpoch = lossValEpoch.mean()\n",
    "\n",
    "        if lossValEpoch < Best_loss_val:\n",
    "            Best_loss_val = lossValEpoch\n",
    "            BestEpoch = i\n",
    "            if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'batch_size':batch_size,\n",
    "                        'batch_size_val':batch_size_val,\n",
    "                        'lr':lr,\n",
    "                        'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'train_loss': lossEpoch,\n",
    "                        'val_loss': lossValEpoch,\n",
    "                        }, './models/' + modelName + '/best_model')\n",
    "            np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n",
    "\n",
    "\n",
    "        printProgressBar(num_batches_val, num_batches_val,\n",
    "                             done=\"[Validation] Epoch: {}, LossG: {:.4f}, Acc: {}\".format(i,lossValEpoch,accuracy_val))\n",
    "        \n",
    "def LoadTraining(modelName, n_epochs):\n",
    "    if os.path.exists('./models/'+modelName+'/best_model'):\n",
    "        checkpoint = torch.load('./models/'+modelName+'/best_model')\n",
    "    else :\n",
    "        batch_size = 16\n",
    "        batch_size_val = 4\n",
    "        lr = 0.001\n",
    "        checkpoint = {\n",
    "            'epoch': 0,\n",
    "            'batch_size': batch_size,\n",
    "            'batch_size_val':batch_size_val,\n",
    "            'lr':lr,\n",
    "            'model_state_dict': None,\n",
    "            'optimizer_state_dict': None,\n",
    "            'train_loss': 0,\n",
    "            'val_loss': 1000,\n",
    "            }\n",
    "    \n",
    "    runTraining(modelName, checkpoint, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Training] Epoch: 0, LossG: 1.9054, Acc: 0.044680277506510414                                                \n",
      "[Validation] Epoch: 0 [DONE]                                 \n",
      "[Validation] Epoch: 0, LossG: 1.4326, Acc: 0.027099609375                                                    \n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "[Training] Epoch: 1, LossG: 1.7737, Acc: 0.03450139363606771                                                 \n",
      "[Validation] Epoch: 1 [DONE]                                 \n",
      "[Validation] Epoch: 1, LossG: 1.4144, Acc: 0.16558074951171875                                               \n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "[Training] Epoch: 2, LossG: 1.6815, Acc: 0.09728240966796875                                                 \n",
      "[Validation] Epoch: 2 [DONE]                                 \n",
      "[Validation] Epoch: 2, LossG: 1.3853, Acc: 0.35748291015625                                                  \n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "[Training] Epoch: 3, LossG: 1.6057, Acc: 0.19282023111979166                                                 \n",
      "[Validation] Epoch: 3 [DONE]                                 \n",
      "[Validation] Epoch: 3, LossG: 1.3755, Acc: 0.5906829833984375                                                \n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "[Training] Epoch: 4, LossG: 1.5390, Acc: 0.2574170430501302                                                  \n",
      "[Validation] Epoch: 4 [DONE]                                 \n",
      "[Validation] Epoch: 4, LossG: 1.3808, Acc: 0.21176910400390625                                               \n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "[Training] Epoch: 5, LossG: 1.4770, Acc: 0.32673899332682294                                                 \n",
      "[Validation] Epoch: 5 [DONE]                                 \n",
      "[Validation] Epoch: 5, LossG: 1.3193, Acc: 0.988189697265625                                                 \n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "[Training] Epoch: 6, LossG: 1.4179, Acc: 0.35063807169596356                                                 \n",
      "[Validation] Epoch: 6 [DONE]                                 \n",
      "[Validation] Epoch: 6, LossG: 1.2856, Acc: 0.990478515625                                                    \n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "[Training] Epoch: 7, LossG: 1.3576, Acc: 0.4039751688639323                                                  \n",
      "[Validation] Epoch: 7 [DONE]                                 \n",
      "[Validation] Epoch: 7, LossG: 1.2564, Acc: 0.9920730590820312                                                \n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "[Training] Epoch: 8, LossG: 1.2953, Acc: 0.7876752217610677                                                  \n",
      "[Validation] Epoch: 8 [DONE]                                 \n",
      "[Validation] Epoch: 8, LossG: 1.2383, Acc: 0.9928131103515625                                                \n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "[Training] Epoch: 9, LossG: 1.2368, Acc: 0.9094823201497396                                                  \n",
      "[Validation] Epoch: 9 [DONE]                                 \n",
      "[Validation] Epoch: 9, LossG: 1.2090, Acc: 0.9945602416992188                                                \n"
     ]
    }
   ],
   "source": [
    "runTraining('Test_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
