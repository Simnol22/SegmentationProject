{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(modelName, checkpoints, n_epochs):\n",
    "    print('-' * 40)\n",
    "    print('~~~~~~~~  Starting the training... ~~~~~~')\n",
    "    print('-' * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = checkpoints['batch_size']\n",
    "    batch_size_val = checkpoints['batch_size_val']\n",
    "    lr = checkpoints['lr']    # Learning Rate\n",
    "    epoch = n_epochs # Number of epochs\n",
    "    start_epoch = checkpoints['epoch']\n",
    "\n",
    "    root_dir = './Data/'\n",
    "\n",
    "    print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                      root_dir,\n",
    "                                                      transform=transform,\n",
    "                                                      mask_transform=mask_transform,\n",
    "                                                      augment=False,\n",
    "                                                      equalize=False)\n",
    "\n",
    "    train_loader_full = DataLoader(train_set_full,\n",
    "                              batch_size=batch_size,\n",
    "                              worker_init_fn=np.random.seed(0),\n",
    "                              num_workers=0,\n",
    "                              shuffle=True)\n",
    "    \n",
    "\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "    val_loader = DataLoader(val_set,\n",
    "                            batch_size=batch_size_val,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4 # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = 'Test_Model'\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "    if checkpoints['model_state_dict'] != None:\n",
    "        net.load_state_dict = checkpoints['model_state_dict']\n",
    "    \n",
    "\n",
    "    print(\"Total params: {0:,}\".format(sum(p.numel() for p in net.parameters() if p.requires_grad)))\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax()\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    if checkpoints['optimizer_state_dict'] != None:\n",
    "        optimizer.load_state_dict = checkpoints['optimizer_state_dict']\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = checkpoints['val_loss']\n",
    "    BestEpoch = 0\n",
    "    \n",
    "    directory = 'Results/Statistics/' + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory)==False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(start_epoch, epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        lossValEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        num_batches_val = len(val_loader)\n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, _ = data\n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            # labels = torch.argmax(labels, dim=1)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            #-- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = net.forward(images)\n",
    "\n",
    "            #-- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            \n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(net_predictions, segmentation_classes) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            lossTotal = CE_loss_value\n",
    "            pred = softMax(net_predictions)\n",
    "            masks = torch.argmax(pred, dim=1)\n",
    "\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            lossTotal.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING \n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches,\n",
    "                             prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(lossTotal))\n",
    "\n",
    "            confmat = ConfusionMatrix(task=\"multiclass\", num_classes=4)\n",
    "            confmat = confmat(net_predictions, segmentation_classes).numpy()\n",
    "            accuracy = np.diag(confmat).sum()/confmat.sum()\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "        printProgressBar(num_batches, num_batches,\n",
    "                             done=\"[Training] Epoch: {}, LossG: {:.4f}, Acc: {}\".format(i,lossEpoch,accuracy))\n",
    "        net.eval()\n",
    "        for j, data_val in enumerate(val_loader):\n",
    "\n",
    "            images_val, labels_val, _ = data_val\n",
    "            labels_val = to_var(labels_val)\n",
    "            images_val = to_var(labels_val)\n",
    "            \n",
    "            net_predictions_val = net.forward(images_val.float())\n",
    "\n",
    "            segmentation_classes_val = getTargetSegmentation(labels_val)\n",
    "\n",
    "            CE_loss_value_val = CE_loss(net_predictions_val, segmentation_classes_val) # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "\n",
    "            confmat_val = ConfusionMatrix(task=\"multiclass\", num_classes=4)\n",
    "            confmat_val = confmat_val(net_predictions_val, segmentation_classes_val).numpy()\n",
    "            accuracy_val = np.diag(confmat_val).sum()/confmat_val.sum()\n",
    "\n",
    "            lossValEpoch.append(CE_loss_value_val.cpu().data.numpy())\n",
    "            printProgressBar(j + 1, num_batches_val,\n",
    "                             prefix=\"[Validation] Epoch: {} \".format(i),\n",
    "                             length=15,\n",
    "                             suffix=\" Loss: {:.4f}, \".format(CE_loss_value_val))\n",
    "\n",
    "        lossValEpoch = np.asarray(lossValEpoch)\n",
    "        lossValEpoch = lossValEpoch.mean()\n",
    "\n",
    "        if lossValEpoch < Best_loss_val:\n",
    "            Best_loss_val = lossValEpoch\n",
    "            BestEpoch = i\n",
    "            if not os.path.exists('./models/' + modelName):\n",
    "                os.makedirs('./models/' + modelName)\n",
    "            torch.save({'epoch': epoch,\n",
    "                        'batch_size':batch_size,\n",
    "                        'batch_size_val':batch_size_val,\n",
    "                        'lr':lr,\n",
    "                        'model_state_dict': net.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'train_loss': lossEpoch,\n",
    "                        'val_loss': lossValEpoch,\n",
    "                        }, './models/' + modelName + '/best_model')\n",
    "            np.save(os.path.join(directory, 'Losses.npy'), lossTotalTraining)\n",
    "\n",
    "\n",
    "        printProgressBar(num_batches_val, num_batches_val,\n",
    "                             done=\"[Validation] Epoch: {}, LossG: {:.4f}, Acc: {}\".format(i,lossValEpoch,accuracy_val))\n",
    "        \n",
    "def runTraining(modelName, n_epochs):\n",
    "    if os.path.exists('./models/'+modelName+'/best_model'):\n",
    "        checkpoint = torch.load('./models/'+modelName+'/best_model')\n",
    "    else :\n",
    "        batch_size = 16\n",
    "        batch_size_val = 4\n",
    "        lr = 0.001\n",
    "        checkpoint = {\n",
    "            'epoch': 0,\n",
    "            'batch_size': batch_size,\n",
    "            'batch_size_val':batch_size_val,\n",
    "            'lr':lr,\n",
    "            'model_state_dict': None,\n",
    "            'optimizer_state_dict': None,\n",
    "            'train_loss': 0,\n",
    "            'val_loss': 1000,\n",
    "            }\n",
    "    \n",
    "    training(modelName, checkpoint, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      " Dataset: ./Data/ \n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "[Training] Epoch: 50 [DONE]                                 \n",
      "[Training] Epoch: 50, LossG: 2.0295, Acc: 0.010618845621744791                                               \n",
      "[Validation] Epoch: 50 [DONE]                                 \n",
      "[Validation] Epoch: 50, LossG: 1.5078, Acc: 6.866455078125e-05                                               \n",
      "[Training] Epoch: 51 [DONE]                                 \n",
      "[Training] Epoch: 51, LossG: 1.8217, Acc: 0.013942718505859375                                               \n",
      "[Validation] Epoch: 51 [DONE]                                 \n",
      "[Validation] Epoch: 51, LossG: 1.4739, Acc: 6.103515625e-05                                                  \n",
      "[Training] Epoch: 52 [DONE]                                 \n",
      "[Training] Epoch: 52, LossG: 1.6680, Acc: 0.009632110595703125                                               \n",
      "[Validation] Epoch: 52 [DONE]                                 \n",
      "[Validation] Epoch: 52, LossG: 1.4072, Acc: 0.00032806396484375                                              \n",
      "[Training] Epoch: 53 [DONE]                                 \n",
      "[Training] Epoch: 53, LossG: 1.5294, Acc: 0.1312255859375                                                    \n",
      "[Validation] Epoch: 53 [DONE]                                 \n",
      "[Validation] Epoch: 53, LossG: 1.3916, Acc: 0.0002593994140625                                               \n",
      "[Training] Epoch: 54 [DONE]                                 \n",
      "[Training] Epoch: 54, LossG: 1.4468, Acc: 0.20925776163736978                                                \n",
      "[Validation] Epoch: 54 [DONE]                                 \n",
      "[Validation] Epoch: 54, LossG: 1.3417, Acc: 0.25388336181640625                                              \n",
      "[Training] Epoch: 55 [DONE]                                 \n",
      "[Training] Epoch: 55, LossG: 1.3806, Acc: 0.655602773030599                                                  \n",
      "[Validation] Epoch: 55 [DONE]                                 \n",
      "[Validation] Epoch: 55, LossG: 1.3126, Acc: 0.9153213500976562                                               \n",
      "[Training] Epoch: 56 [DONE]                                 \n",
      "[Training] Epoch: 56, LossG: 1.3383, Acc: 0.8555157979329427                                                 \n",
      "[Validation] Epoch: 56 [DONE]                                 \n",
      "[Validation] Epoch: 56, LossG: 1.2812, Acc: 0.9903564453125                                                  \n",
      "[Training] Epoch: 57 [DONE]                                 \n",
      "[Training] Epoch: 57, LossG: 1.2922, Acc: 0.925103505452474                                                  \n",
      "[Validation] Epoch: 57 [DONE]                                 \n",
      "[Validation] Epoch: 57, LossG: 1.2565, Acc: 0.991424560546875                                                \n",
      "[Training] Epoch: 58 [DONE]                                 \n",
      "[Training] Epoch: 58, LossG: 1.2632, Acc: 0.8987833658854166                                                 \n",
      "[Validation] Epoch: 58 [DONE]                                 \n",
      "[Validation] Epoch: 58, LossG: 1.2327, Acc: 0.9935073852539062                                               \n",
      "[Training] Epoch: 59 [DONE]                                 \n",
      "[Training] Epoch: 59, LossG: 1.2382, Acc: 0.9672953287760416                                                 \n",
      "[Validation] Epoch: 59 [DONE]                                 \n",
      "[Validation] Epoch: 59, LossG: 1.2151, Acc: 0.9958114624023438                                               \n",
      "[Training] Epoch: 60 [DONE]                                 \n",
      "[Training] Epoch: 60, LossG: 1.2137, Acc: 0.9624773661295573                                                 \n",
      "[Validation] Epoch: 60 [DONE]                                 \n",
      "[Validation] Epoch: 60, LossG: 1.1976, Acc: 0.99615478515625                                                 \n",
      "[Training] Epoch: 61 [DONE]                                 \n",
      "[Training] Epoch: 61, LossG: 1.1926, Acc: 0.9746805826822916                                                 \n",
      "[Validation] Epoch: 61 [DONE]                                 \n",
      "[Validation] Epoch: 61, LossG: 1.1812, Acc: 0.99658203125                                                    \n",
      "[Training] Epoch: 62 [DONE]                                 \n",
      "[Training] Epoch: 62, LossG: 1.1758, Acc: 0.9772631327311198                                                 \n",
      "[Validation] Epoch: 62 [DONE]                                 \n",
      "[Validation] Epoch: 62, LossG: 1.1657, Acc: 0.9966506958007812                                               \n",
      "[Training] Epoch: 63 [DONE]                                 \n",
      "[Training] Epoch: 63, LossG: 1.1596, Acc: 0.9719390869140625                                                 \n",
      "[Validation] Epoch: 63 [DONE]                                 \n",
      "[Validation] Epoch: 63, LossG: 1.1499, Acc: 0.9967041015625                                                  \n",
      "[Training] Epoch: 64 [DONE]                                 \n",
      "[Training] Epoch: 64, LossG: 1.1429, Acc: 0.9755528767903646                                                 \n",
      "[Validation] Epoch: 64 [DONE]                                 \n",
      "[Validation] Epoch: 64, LossG: 1.1342, Acc: 0.9967117309570312                                               \n",
      "[Training] Epoch: 65 [DONE]                                 \n",
      "[Training] Epoch: 65, LossG: 1.1277, Acc: 0.9699579874674479                                                 \n",
      "[Validation] Epoch: 65 [DONE]                                 \n",
      "[Validation] Epoch: 65, LossG: 1.1189, Acc: 0.9967193603515625                                               \n",
      "[Training] Epoch: 66 [DONE]                                 \n",
      "[Training] Epoch: 66, LossG: 1.1116, Acc: 0.9748992919921875                                                 \n",
      "[Validation] Epoch: 66 [DONE]                                 \n",
      "[Validation] Epoch: 66, LossG: 1.1036, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 67 [DONE]                                 \n",
      "[Training] Epoch: 67, LossG: 1.0963, Acc: 0.9674860636393229                                                 \n",
      "[Validation] Epoch: 67 [DONE]                                 \n",
      "[Validation] Epoch: 67, LossG: 1.0888, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 68 [DONE]                                 \n",
      "[Training] Epoch: 68, LossG: 1.0810, Acc: 0.9744720458984375                                                 \n",
      "[Validation] Epoch: 68 [DONE]                                 \n",
      "[Validation] Epoch: 68, LossG: 1.0739, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 69 [DONE]                                 \n",
      "[Training] Epoch: 69, LossG: 1.0662, Acc: 0.9765307108561198                                                 \n",
      "[Validation] Epoch: 69 [DONE]                                 \n",
      "[Validation] Epoch: 69, LossG: 1.0594, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 70 [DONE]                                 \n",
      "[Training] Epoch: 70, LossG: 1.0526, Acc: 0.9778976440429688                                                 \n",
      "[Validation] Epoch: 70 [DONE]                                 \n",
      "[Validation] Epoch: 70, LossG: 1.0448, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 71 [DONE]                                 \n",
      "[Training] Epoch: 71, LossG: 1.0378, Acc: 0.9705403645833334                                                 \n",
      "[Validation] Epoch: 71 [DONE]                                 \n",
      "[Validation] Epoch: 71, LossG: 1.0305, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 72 [DONE]                                 \n",
      "[Training] Epoch: 72, LossG: 1.0238, Acc: 0.9757703145345052                                                 \n",
      "[Validation] Epoch: 72 [DONE]                                 \n",
      "[Validation] Epoch: 72, LossG: 1.0164, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 73 [DONE]                                 \n",
      "[Training] Epoch: 73, LossG: 1.0091, Acc: 0.9669748942057291                                                 \n",
      "[Validation] Epoch: 73 [DONE]                                 \n",
      "[Validation] Epoch: 73, LossG: 1.0025, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 74 [DONE]                                 \n",
      "[Training] Epoch: 74, LossG: 0.9950, Acc: 0.968390146891276                                                  \n",
      "[Validation] Epoch: 74 [DONE]                                 \n",
      "[Validation] Epoch: 74, LossG: 0.9887, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 75 [DONE]                                 \n",
      "[Training] Epoch: 75, LossG: 0.9811, Acc: 0.963097890218099                                                  \n",
      "[Validation] Epoch: 75 [DONE]                                 \n",
      "[Validation] Epoch: 75, LossG: 0.9751, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 76 [DONE]                                 \n",
      "[Training] Epoch: 76, LossG: 0.9675, Acc: 0.9680709838867188                                                 \n",
      "[Validation] Epoch: 76 [DONE]                                 \n",
      "[Validation] Epoch: 76, LossG: 0.9618, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 77 [DONE]                                 \n",
      "[Training] Epoch: 77, LossG: 0.9542, Acc: 0.9778823852539062                                                 \n",
      "[Validation] Epoch: 77 [DONE]                                 \n",
      "[Validation] Epoch: 77, LossG: 0.9486, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 78 [DONE]                                 \n",
      "[Training] Epoch: 78, LossG: 0.9409, Acc: 0.9770927429199219                                                 \n",
      "[Validation] Epoch: 78 [DONE]                                 \n",
      "[Validation] Epoch: 78, LossG: 0.9356, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 79 [DONE]                                 \n",
      "[Training] Epoch: 79, LossG: 0.9280, Acc: 0.9606539408365885                                                 \n",
      "[Validation] Epoch: 79 [DONE]                                 \n",
      "[Validation] Epoch: 79, LossG: 0.9227, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 80 [DONE]                                 \n",
      "[Training] Epoch: 80, LossG: 0.9150, Acc: 0.9730631510416666                                                 \n",
      "[Validation] Epoch: 80 [DONE]                                 \n",
      "[Validation] Epoch: 80, LossG: 0.9101, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 81 [DONE]                                 \n",
      "[Training] Epoch: 81, LossG: 0.9026, Acc: 0.976385752360026                                                  \n",
      "[Validation] Epoch: 81 [DONE]                                 \n",
      "[Validation] Epoch: 81, LossG: 0.8977, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 82 [DONE]                                 \n",
      "[Training] Epoch: 82, LossG: 0.8903, Acc: 0.96844482421875                                                   \n",
      "[Validation] Epoch: 82 [DONE]                                 \n",
      "[Validation] Epoch: 82, LossG: 0.8854, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 83 [DONE]                                 \n",
      "[Training] Epoch: 83, LossG: 0.8779, Acc: 0.9642372131347656                                                 \n",
      "[Validation] Epoch: 83 [DONE]                                 \n",
      "[Validation] Epoch: 83, LossG: 0.8733, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 84 [DONE]                                 \n",
      "[Training] Epoch: 84, LossG: 0.8657, Acc: 0.9706929524739584                                                 \n",
      "[Validation] Epoch: 84 [DONE]                                 \n",
      "[Validation] Epoch: 84, LossG: 0.8614, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 85 [DONE]                                 \n",
      "[Training] Epoch: 85, LossG: 0.8538, Acc: 0.9703572591145834                                                 \n",
      "[Validation] Epoch: 85 [DONE]                                 \n",
      "[Validation] Epoch: 85, LossG: 0.8496, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 86 [DONE]                                 \n",
      "[Training] Epoch: 86, LossG: 0.8421, Acc: 0.966131846110026                                                  \n",
      "[Validation] Epoch: 86 [DONE]                                 \n",
      "[Validation] Epoch: 86, LossG: 0.8381, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 87 [DONE]                                 \n",
      "[Training] Epoch: 87, LossG: 0.8305, Acc: 0.9692484537760416                                                 \n",
      "[Validation] Epoch: 87 [DONE]                                 \n",
      "[Validation] Epoch: 87, LossG: 0.8267, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 88 [DONE]                                 \n",
      "[Training] Epoch: 88, LossG: 0.8191, Acc: 0.9744834899902344                                                 \n",
      "[Validation] Epoch: 88 [DONE]                                 \n",
      "[Validation] Epoch: 88, LossG: 0.8155, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 89 [DONE]                                 \n",
      "[Training] Epoch: 89, LossG: 0.8080, Acc: 0.9659105936686198                                                 \n",
      "[Validation] Epoch: 89 [DONE]                                 \n",
      "[Validation] Epoch: 89, LossG: 0.8044, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 90 [DONE]                                 \n",
      "[Training] Epoch: 90, LossG: 0.7969, Acc: 0.9714520772298177                                                 \n",
      "[Validation] Epoch: 90 [DONE]                                 \n",
      "[Validation] Epoch: 90, LossG: 0.7936, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 91 [DONE]                                 \n",
      "[Training] Epoch: 91, LossG: 0.7860, Acc: 0.9773330688476562                                                 \n",
      "[Validation] Epoch: 91 [DONE]                                 \n",
      "[Validation] Epoch: 91, LossG: 0.7829, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 92 [DONE]                                 \n",
      "[Training] Epoch: 92, LossG: 0.7753, Acc: 0.977654774983724                                                  \n",
      "[Validation] Epoch: 92 [DONE]                                 \n",
      "[Validation] Epoch: 92, LossG: 0.7724, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 93 [DONE]                                 \n",
      "[Training] Epoch: 93, LossG: 0.7656, Acc: 0.9600143432617188                                                 \n",
      "[Validation] Epoch: 93 [DONE]                                 \n",
      "[Validation] Epoch: 93, LossG: 0.7620, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 94 [DONE]                                 \n",
      "[Training] Epoch: 94, LossG: 0.7547, Acc: 0.9727185567220052                                                 \n",
      "[Validation] Epoch: 94 [DONE]                                 \n",
      "[Validation] Epoch: 94, LossG: 0.7518, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 95 [DONE]                                 \n",
      "[Training] Epoch: 95, LossG: 0.7447, Acc: 0.9664344787597656                                                 \n",
      "[Validation] Epoch: 95 [DONE]                                 \n",
      "[Validation] Epoch: 95, LossG: 0.7418, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 96 [DONE]                                 \n",
      "[Training] Epoch: 96, LossG: 0.7346, Acc: 0.9721260070800781                                                 \n",
      "[Validation] Epoch: 96 [DONE]                                 \n",
      "[Validation] Epoch: 96, LossG: 0.7320, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 97 [DONE]                                 \n",
      "[Training] Epoch: 97, LossG: 0.7245, Acc: 0.9755427042643229                                                 \n",
      "[Validation] Epoch: 97 [DONE]                                 \n",
      "[Validation] Epoch: 97, LossG: 0.7223, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 98 [DONE]                                 \n",
      "[Training] Epoch: 98, LossG: 0.7150, Acc: 0.9660555521647135                                                 \n",
      "[Validation] Epoch: 98 [DONE]                                 \n",
      "[Validation] Epoch: 98, LossG: 0.7127, Acc: 0.9967269897460938                                               \n",
      "[Training] Epoch: 99 [DONE]                                 \n",
      "[Training] Epoch: 99, LossG: 0.7055, Acc: 0.9664459228515625                                                 \n",
      "[Validation] Epoch: 99 [DONE]                                 \n",
      "[Validation] Epoch: 99, LossG: 0.7033, Acc: 0.9967269897460938                                               \n"
     ]
    }
   ],
   "source": [
    "runTraining('Test_model', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
